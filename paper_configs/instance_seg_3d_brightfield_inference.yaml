mode: inference

data:
  inference_input:
    dir:  "/PATH/TO/DATA/"   #ADD-YOURS
    reader_params:
      dimension_order_out: "ZYX"
      C: 0
      T: 0
  inference_output:
    path:  "/OUTPUT/PATH/"   #ADD-YOURS
  preprocess:      
    - module_name: mmv_im2im.preprocessing.transforms
      func_name: norm_around_center
      params:
        min_z: 32
  postprocess:
    - module_name: mmv_im2im.postprocessing.embedseg_cluster
      func_name: generate_instance_clusters
      params:
        grid_x: 1024
        grid_y: 1024
        grid_z: 80
        pixel_x: 1
        pixel_y: 1
        pixel_z: 1
        n_sigma: 3
        seed_thresh: 0.5
        min_mask_sum: 2
        min_unclustered_sum: 2
        min_object_size: 2

model:
  framework: embedseg
  net:
    module_name: aicsmlsegment.NetworkArchitecture.unet_xy_zoom_0pad_single
    func_name: UNet3D
    params:
      in_channel: 1
      n_classes: 7
      down_ratio: 4
  checkpoint: "/PATH/TO/LOGS/FOLDER/lightning_logs/version_0/checkpoints/best.ckpt"   #ADD-YOURS
  model_extra:
    sliding_window_params:
      roi_size: [32, 128, 128]
      sw_batch_size: 4
      overlap: 0.2
      mode: "gaussian"
trainer:
  params:
    gpus: 1
    precision: 16
