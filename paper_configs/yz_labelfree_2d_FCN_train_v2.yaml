mode: train

data:
  category: "pair"
  data_path: /mnt/eternus/users/Jianxu/projects/im2im_experiments_v2/data/labelfree2D/train
  dataloader:
    train:
      dataloader_params:
        batch_size: 2
        pin_memory: True
        num_workers: 4

  preprocess:
    - module_name: monai.transforms
      func_name: LoadImaged
      params:
        keys: ["IM", "GT"]
        dimension_order_out: "YX"
        C: 0
        T: 0
        Z: 0
    - module_name: monai.transforms
      func_name: AddChanneld
      params:
        keys: ["IM", "GT"]
    - module_name: monai.transforms
      func_name: NormalizeIntensityd
      params:
        keys: ["IM", "GT"]            
    - module_name: monai.transforms
      func_name: RandSpatialCropSamplesd
      params:
        keys: ["IM", "GT"]
        random_size: False
        num_samples: 4
        roi_size: [256, 256]
    - module_name: monai.transforms
      func_name: EnsureTyped
      params:
        keys: ["IM", "GT"]
  augmentation:
    - module_name: monai.transforms
      func_name: RandFlipd
      params:
        prob: 0.5
        keys: ["IM", "GT"]

model:
  framework: FCN
  net:
    module_name: mmv_im2im.models.nets.convnext_2d_v2
    func_name: Net
    params:
      in_channels: 1
      n_channels: 64
      n_classes: 1
      exp_r: 4
      kernel_size: 3
      deep_supervision: False
      do_res: False
      do_res_up_down: True
      block_counts: [2,2,6,2,2,2,6,2,2]
      norm_type: "group"
  criterion:
    module_name: torch.nn
    func_name: MSELoss
    params:
      reduction: 'mean'
  optimizer:
    module_name: torch.optim
    func_name: Adam  # AdamW
    params:
      lr: 0.001
      weight_decay: 0.0005
  scheduler:
    module_name: torch.optim.lr_scheduler
    func_name: ExponentialLR
    params:
      gamma: 0.98
trainer:
  verbose: True
  params:
    accelerator: "gpu"
    devices: 1
    precision: 32
    max_epochs: 30
    detect_anomaly: True
  callbacks:
    - module_name: lightning.pytorch.callbacks.early_stopping
      func_name: EarlyStopping
      params:
        monitor: 'val_loss_epoch'
        patience: 50 
        verbose: True
    - module_name: lightning.pytorch.callbacks.model_checkpoint
      func_name: ModelCheckpoint
      params:
        monitor: 'val_loss_epoch'
        save_last: True
        save_weights_only: True 
