mode: train

data:
  category: "pair"
  data_path: /mnt/eternus/users/Jianxu/projects/im2im_experiments_v1/data/semantic3D/train_fbl/ 
  dataloader:
    train:
      dataloader_params:
        batch_size: 1
        pin_memory: False
        num_workers: 4

  preprocess:
    - module_name: monai.transforms
      func_name: LoadImaged
      params:
        keys: ["IM"]
        dimension_order_out: "ZYX"
        C: 0
        T: 0
    - module_name: monai.transforms
      func_name: LoadImaged
      params:
        keys: ["GT"]
        dtype: int
        dimension_order_out: "ZYX"
        C: 0
        T: 0
    - module_name: monai.transforms
      func_name: AddChanneld
      params:
        keys: ["IM", "GT"]
    - module_name: monai.transforms
      func_name: NormalizeIntensityd
      params:
        keys: ["IM"]
    - module_name: monai.transforms
      func_name: RandSpatialCropSamplesd
      params:
        keys: ["IM", "GT"]
        random_size: False
        num_samples: 1
        roi_size: [32, 256, 256]
    - module_name: monai.transforms
      func_name: EnsureTyped
      params:
        keys: ["IM", "GT"]
  augmentation:
    - module_name: monai.transforms
      func_name: RandFlipd
      params:
        prob: 0.5
        keys: ["IM", "GT"]
    - module_name: monai.transforms
      func_name: RandHistogramShiftd
      params:
        prob: 0.2
        keys: ["IM"]

model:
  framework: FCN
  net:
    module_name: mmv_im2im.models.nets.convnext_3d
    func_name: Net
    params:
      in_channels: 1
      n_channels: 32
      n_classes: 2
      exp_r: 1
      kernel_size: 3
      deep_supervision: False
      do_res: True
      do_res_up_down: True
      block_counts: [2,2,2,2,2,2,2,2,2]
  criterion:
    module_name: monai.losses
    func_name: GeneralizedDiceFocalLoss
    params:
      softmax: True
      to_onehot_y: True
  optimizer:
    module_name: torch.optim
    func_name: Adam  # AdamW
    params:
      lr: 0.001
      weight_decay: 0.0005
  scheduler:
    module_name: torch.optim.lr_scheduler
    func_name: ExponentialLR
    params:
      gamma: 0.98
trainer:
  verbose: True
  params:
    accelerator: "gpu"
    devices: 1
    precision: 32
    max_epochs: 100
    detect_anomaly: True
    # gradient_clip_val: 0.5
    # gradient_clip_algorithm: "value"
  callbacks:
    - module_name: lightning.pytorch.callbacks.early_stopping
      func_name: EarlyStopping
      params:
        monitor: 'val_loss_epoch'
        patience: 50 
        verbose: True
    - module_name: lightning.pytorch.callbacks.model_checkpoint
      func_name: ModelCheckpoint
      params:
        save_last: True
        save_weights_only: True 