
# everything about data
data:
  category: "pair"
  # data_path: "/mnt/data/xyz.csv"
  data_path: "~/ambiomgroupdrive/Jianxu/data/labelfree_lamin/training_data"
  # data_path:
  #   source_path:
  #   target_path:
  #   costmap_path: optional
  #   image_type: "tiff"
  dataloader:
    train_val_ratio: 0.1
    train:
      dataloader_type:
        module_name: monai.data
        func_name: PersistentDataset
      dataset_params: 
        cache_dir: "./tmp"
      dataloader_params:
        batch_size: 8
        pin_memory: True
        num_workers: 4
      partial_loader:
        reload_n_epoch: 10
        load_percentage: 0.5
    val:
      dataloader_type:
        module_name: monai.data
        func_name: PersistentDataset
      dataset_params: 
        cache_dir: "./tmp"
      dataloader_params:
        batch_size: 1
        pin_memory: True
        num_workers: 4
  preprocess:
    - module_name: monai.transforms
      func_name: LoadImaged
      params:
        keys: ["IM", "GT"]
        dimension_order_out: "ZYX"
        C: 0
        T: 0
    - module_name: monai.transforms
      func_name: AddChanneld
      params:
        keys: ["IM", "GT"]
    - module_name: monai.transforms
      func_name: ScaleIntensityRanged
      params:
        keys: ["IM"]
        a_min: 0
        a_max: 255
        b_min: 0.0
        b_max: 1.0
        clip: True
    - module_name: monai.transforms
      func_name: RandSpatialCropSamplesd
      params:
        keys: ["IM", "GT"]
        random_size: False
        num_samples: 4
        roi_size: [32, 64, 64]
    - module_name: monai.transforms
      func_name: EnsureTyped
      params:
        keys: ["IM", "GT"]
  augmentation:
    - module_name: monai.transforms
      func_name: RandFlipd
      params:
        prob: 0.5
        keys: ["IM", "GT"]

model:
  category: FCN
  net:
    module_name: monai.networks.nets
    func_name: UNet
    params:
      spatial_dims: 3
      in_channels: 1
      out_channels: 1
      channels: [8, 16, 32, 64]
      strides: [2, 2, 2]
  criterion:
    module_name: torch.nn
    func_name: MSELoss
    params:
      reduction: 'mean'
  optimizer:
    module_name: torch.optim
    func_name: Adam  # AdamW
    params:
      lr: 0.001
      weight_decay: 0.0005
  scheduler:
    module_name: torch.optim.lr_scheduler
    func_name: ExponentialLR
    params:
      gamma: 0.98
# training
training:
  params:
    gpus: 1
    precision: 16
    stochastic_weight_avg: True
    max_epochs: 5
#  callbacks:
#    - module_name: pytorch_lightning.callbacks.early_stopping
#      func_name: EarlyStopping
#      params:
#        monitor: 'val_loss'
    