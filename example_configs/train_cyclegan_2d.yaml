
# everything about data
data:
  category: "unpair"
  spatial_dims: 3
  target_type: "Image" # "Label" or "Image
  target_reader_params:
    dimension_order_out: "ZYX"
    C: 0
    T: 0
  source_type: "Image" # "Label" or "Image
  source_reader_params:
    dimension_order_out: "ZYX"
    C: 0
    T: 0
  # data_path: "/mnt/data/xyz.csv"
  data_path: "~/ambiomgroupdrive/Jianxu/data/labelfree_lamin/training_data"
  # data_path:
  #   source_path:
  #   target_path:
  #   costmap_path: optional
  #   image_type: "tiff"
  dataloader_patch_queue:  # where to use IO queue in
    sampler:
      name: UniformSampler
      params:
        patch_size: [32, 256, 256]
    params:
      num_workers: 4
      max_length: 800
      samples_per_volume: 8
  dataloader_params:
    train:
      batch_size: 8
      pin_memory: True
      num_workers: 0  # if dataload_path_queue is used, num_workers must be 0 here
    val:
      batch_size: 1
      num_workers: 1
  train_val_ratio: 0.1
  preprocess:
    - module_name: torchio
      func_name: ZNormalization
  augmentation:
    - module_name: torchio
      func_name: RandomFlip
      params:
        axes: [1, 2]
        flip_probability: 0.5
#    - module_name: torchio
#      func_name: RandomAffine
#      params:
#        degrees: [0, 0, 0, 90, 0, 90]
#        p: 0.5
# model
model:
  category: cyclegan
  net:
    generator:
      module_name: monai.networks.nets
      func_name: UNet
      params:
        spatial_dims: 2
        in_channels: 1
        out_channels: 1
        channels: [8, 16, 32, 64]
        strides: [2, 2]
    discriminator:
      module_name: monai.networks.nets
      func_name: UNet
      params:
        spatial_dims: 3
        in_channels: 1
        out_channels: 1
        channels: [8, 16, 32, 64]
        strides: [2, 2, 2]
  criterion:
    gan_loss:
      module_name: torch.nn
      func_name: MSELoss
      params:
        reduction: 'mean'
    cycle_loss:
      module_name: torch.nn
      func_name: L1Loss
      params:
        reduction: 'mean'
    identity_loss:
      module_name: torch.nn
      func_name: L1Loss
      params:
        reduction: 'mean'
    weights:
      gan_loss: 1
      cycle_loss: 10
      identify_loss: 2
    fake_pool_size: 50
  optimizer:
    generator:
      module_name: torch.optim
      func_name: Adam  # AdamW
      params:
        lr: 0.001
        weight_decay: 0.0005
    discriminator:
      module_name: torch.optim
      func_name: Adam  # AdamW
      params:
        lr: 0.001
        weight_decay: 0.0005
  scheduler:
    generator:
      module_name: torch.optim.lr_scheduler
      func_name: ExponentialLR
      params:
        gamma: 0.98
    discriminator:
      module_name: torch.optim.lr_scheduler
      func_name: ExponentialLR
      params:
        gamma: 0.98
# training
training:
  params:
    gpus: 1
    precision: 16
    stochastic_weight_avg: True
#  callbacks:
#    - module_name: pytorch_lightning.callbacks.early_stopping
#      func_name: EarlyStopping
#      params:
#        monitor: 'val_loss'
    