
# everything about data
data:
  category: "pair_3d"
  target_type: "Image" # "Label" or "Image
  params:
      data_type: "tiff"
  target_reader_params:
    dimension_order_out: "ZXY"
    C: 1
    T: 1
  source_type: "Image" # "Label" or "Image
  params:
      data_type: "tiff"
  source_reader_params:
    dimension_order_out: "ZXY"
    C: 1
    T: 1
  # data_path: "/mnt/data/xyz.csv"
  data_path: "~/ambiomgroupdrive/Sai/data/paired_dataset/training_data"
  # data_path:
  #   source_path:
  #   target_path:
  #   costmap_path: optional
  #   image_type: "tiff"
  dataloader_patch_queue:  # where to use IO queue in
    sampler:
      name: UniformSampler
      func_name: RescaleIntensity
      params:
        patch_size: [32, 128, 128]
    params:
      num_workers: 4
      max_length: 360
      samples_per_volume: 8
  dataloader_params:
    train:
      batch_size: 2
      pin_memory: True
      num_workers: 0  # if dataload_path_queue is used, num_workers must be 0 here
    val:
      batch_size: 1
      num_workers: 1
  train_val_ratio: 0.2
  preprocess:
    - module_name: torchio
      func_name: ZNormalization
  augmentation:
    - module_name: torchio
      func_name: RandomAffine
      params:
        p: 0.5
    - module_name: torchio
      func_name: RandomAffine
      params:
        degrees: [0, 0, 0, 90, 0, 90]
        p: 0.5
# model
model:
  category: FCN
  net:
    module_name: monai.networks.nets
    func_name: UNet
    params:
      spatial_dims: 3
      in_channels: 1
      out_channels: 1
      channels: [8, 16, 32, 64]
      strides: [2, 2, 2]
  criterion:
    module_name: torch.nn
    func_name: MSELoss
    params:
      reduction: 'mean'
  optimizer:
    module_name: torch.optim
    func_name: Adam  # AdamW
    params:
      lr: 0.001
  sliding_window_params:
    dims_max: [1, 32, 256, 256]
    overlaps: [0, 6, 12, 12]

  category: pix2pixGAN
  generator_net :
    module_name: mmv_im2im.models.pix2pix_generator_discriminator_3D
    func_name: UNetGenerator
    params: 
      in_channels: 1
      out_channels: 1

  discriminator_net:
    module_name: mmv_im2im.models.pix2pix_generator_discriminator_3D
    func_name: Discriminator
    params:
      in_channels: 1

  sliding_window_params:
    dims_max: [1, 32, 128, 128]
    overlaps: [0, 6, 12, 12]


  L1_criterion:
    module_name: torch.nn
    func_name: L1Loss
  BCE_criterion:
    module_name: torch.nn
    func_name: BCEWithLogitsLoss

    

  optimizer: 
    module_name: torch.optim
    func_name: Adam
    params: 
      lr: 0.0002
      betas: [0.5,0.999]


# training
training:
  params:
    gpus: 1
    precision: 16
    max_epochs: 100
    auto_lr_find: True
    
  # callbacks: 
  #   module_name: pl_bolts.callbacks
  #   func_name: PrintTableMetricsCallback

  #   module_name: pytorch_lightning.callbacks
  #   func_name: ModelCheckpoint
  #   params:
  #     monitor: 'val_loss'

    # callbacks: 
    #   module_name: pytorch_lightning.callbacks
    #   func_name: ModelCheckpoint
    #     monitor: 'val_loss'
        

    # strategy: 'dp'

#checkpoint_path:   ~/ambiomgroupdrive/Sai/mmv_im2im_fork/lightning_logs/version_104/checkpoints/epoch=9-step=899.ckpt
    #stochastic_weight_avg: True
#  callbacks:
#    - module_name: pytorch_lightning.callbacks.early_stopping
#      func_name: EarlyStopping
#        monitor: 'val_loss'
    